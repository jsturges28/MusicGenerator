Model: "encoder"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 encoder_input (InputLayer)     [(None, 256, 64, 1)  0           []                               
                                ]                                                                 
                                                                                                  
 encoder_conv_layer_1 (Conv2D)  (None, 128, 32, 512  5120        ['encoder_input[0][0]']          
                                )                                                                 
                                                                                                  
 encoder_relu_1 (ReLU)          (None, 128, 32, 512  0           ['encoder_conv_layer_1[0][0]']   
                                )                                                                 
                                                                                                  
 encoder_bn_1 (BatchNormalizati  (None, 128, 32, 512  2048       ['encoder_relu_1[0][0]']         
 on)                            )                                                                 
                                                                                                  
 encoder_conv_layer_2 (Conv2D)  (None, 64, 16, 256)  1179904     ['encoder_bn_1[0][0]']           
                                                                                                  
 encoder_relu_2 (ReLU)          (None, 64, 16, 256)  0           ['encoder_conv_layer_2[0][0]']   
                                                                                                  
 encoder_bn_2 (BatchNormalizati  (None, 64, 16, 256)  1024       ['encoder_relu_2[0][0]']         
 on)                                                                                              
                                                                                                  
 encoder_conv_layer_3 (Conv2D)  (None, 32, 8, 128)   295040      ['encoder_bn_2[0][0]']           
                                                                                                  
 encoder_relu_3 (ReLU)          (None, 32, 8, 128)   0           ['encoder_conv_layer_3[0][0]']   
                                                                                                  
 encoder_bn_3 (BatchNormalizati  (None, 32, 8, 128)  512         ['encoder_relu_3[0][0]']         
 on)                                                                                              
                                                                                                  
 encoder_conv_layer_4 (Conv2D)  (None, 16, 4, 64)    73792       ['encoder_bn_3[0][0]']           
                                                                                                  
 encoder_relu_4 (ReLU)          (None, 16, 4, 64)    0           ['encoder_conv_layer_4[0][0]']   
                                                                                                  
 encoder_bn_4 (BatchNormalizati  (None, 16, 4, 64)   256         ['encoder_relu_4[0][0]']         
 on)                                                                                              
                                                                                                  
 encoder_conv_layer_5 (Conv2D)  (None, 8, 4, 32)     18464       ['encoder_bn_4[0][0]']           
                                                                                                  
 encoder_relu_5 (ReLU)          (None, 8, 4, 32)     0           ['encoder_conv_layer_5[0][0]']   
                                                                                                  
 encoder_bn_5 (BatchNormalizati  (None, 8, 4, 32)    128         ['encoder_relu_5[0][0]']         
 on)                                                                                              
                                                                                                  
 flatten (Flatten)              (None, 1024)         0           ['encoder_bn_5[0][0]']           
                                                                                                  
 mu (Dense)                     (None, 128)          131200      ['flatten[0][0]']                
                                                                                                  
 log_variance (Dense)           (None, 128)          131200      ['flatten[0][0]']                
                                                                                                  
 encoder_output (Lambda)        (None, 128)          0           ['mu[0][0]',                     
                                                                  'log_variance[0][0]']           
                                                                                                  
==================================================================================================
Total params: 1,838,688
Trainable params: 1,836,704
Non-trainable params: 1,984
__________________________________________________________________________________________________
Model: "decoder"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 decoder_input (InputLayer)  [(None, 128)]             0         
                                                                 
 decoder_dense (Dense)       (None, 1024)              132096    
                                                                 
 reshape (Reshape)           (None, 8, 4, 32)          0         
                                                                 
 decoder_conv_transpose_laye  (None, 16, 4, 32)        9248      
 r_1 (Conv2DTranspose)                                           
                                                                 
 decoder_relu_1 (ReLU)       (None, 16, 4, 32)         0         
                                                                 
 decoder_bn_1 (BatchNormaliz  (None, 16, 4, 32)        128       
 ation)                                                          
                                                                 
 decoder_conv_transpose_laye  (None, 32, 8, 64)        18496     
 r_2 (Conv2DTranspose)                                           
                                                                 
 decoder_relu_2 (ReLU)       (None, 32, 8, 64)         0         
                                                                 
 decoder_bn_2 (BatchNormaliz  (None, 32, 8, 64)        256       
 ation)                                                          
                                                                 
 decoder_conv_transpose_laye  (None, 64, 16, 128)      73856     
 r_3 (Conv2DTranspose)                                           
                                                                 
 decoder_relu_3 (ReLU)       (None, 64, 16, 128)       0         
                                                                 
 decoder_bn_3 (BatchNormaliz  (None, 64, 16, 128)      512       
 ation)                                                          
                                                                 
 decoder_conv_transpose_laye  (None, 128, 32, 256)     295168    
 r_4 (Conv2DTranspose)                                           
                                                                 
 decoder_relu_4 (ReLU)       (None, 128, 32, 256)      0         
                                                                 
 decoder_bn_4 (BatchNormaliz  (None, 128, 32, 256)     1024      
 ation)                                                          
                                                                 
 decoder_conv_transpose_laye  (None, 256, 64, 1)       2305      
 r_5 (Conv2DTranspose)                                           
                                                                 
 sigmoid_layer (Activation)  (None, 256, 64, 1)        0         
                                                                 
=================================================================
Total params: 533,089
Trainable params: 532,129
Non-trainable params: 960
_________________________________________________________________
Model: "autoencoder"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 encoder_input (InputLayer)  [(None, 256, 64, 1)]      0         
                                                                 
 encoder (Functional)        (None, 128)               1838688   
                                                                 
 decoder (Functional)        (None, 256, 64, 1)        533089    
                                                                 
=================================================================
Total params: 2,371,777
Trainable params: 2,368,833
Non-trainable params: 2,944
_________________________________________________________________
Train on 3000 samples
Epoch 1/2
  64/3000 [..............................] - ETA: 11:58 - loss: 228218.3125 - MeanSquaredError: 0.2280 - KLDivergence: 0.0038 128/3000 [>.............................] - ETA: 6:21 - loss: 226464.4453 - MeanSquaredError: 0.2263 - KLDivergence: 8.4457e-04 192/3000 [>.............................] - ETA: 4:27 - loss: 223108.7292 - MeanSquaredError: 0.2229 - KLDivergence: -4.3403e-04 256/3000 [=>............................] - ETA: 3:30 - loss: 220285.2695 - MeanSquaredError: 0.2201 - KLDivergence: -0.0019     320/3000 [==>...........................] - ETA: 2:55 - loss: 217827.3344 - MeanSquaredError: 0.2176 - KLDivergence: -0.0033 384/3000 [==>...........................] - ETA: 2:31 - loss: 214657.5026 - MeanSquaredError: 0.2144 - KLDivergence: -0.0058 448/3000 [===>..........................] - ETA: 2:14 - loss: 211859.5938 - MeanSquaredError: 0.2116 - KLDivergence: -0.0081 512/3000 [====>.........................] - ETA: 2:01 - loss: 209255.5312 - MeanSquaredError: 0.2090 - KLDivergence: -0.0102 576/3000 [====>.........................] - ETA: 1:50 - loss: 206407.6250 - MeanSquaredError: 0.2062 - KLDivergence: -0.0126 640/3000 [=====>........................] - ETA: 1:41 - loss: 203454.4953 - MeanSquaredError: 0.2032 - KLDivergence: -0.0148 704/3000 [======>.......................] - ETA: 1:34 - loss: 200549.9730 - MeanSquaredError: 0.2003 - KLDivergence: -0.0169 768/3000 [======>.......................] - ETA: 1:27 - loss: 197661.5612 - MeanSquaredError: 0.1974 - KLDivergence: -0.0189 832/3000 [=======>......................] - ETA: 1:22 - loss: 194733.5180 - MeanSquaredError: 0.1944 - KLDivergence: -0.0207 896/3000 [=======>......................] - ETA: 1:17 - loss: 191540.0078 - MeanSquaredError: 0.1912 - KLDivergence: -0.0224 960/3000 [========>.....................] - ETA: 1:12 - loss: 188565.1365 - MeanSquaredError: 0.1882 - KLDivergence: -0.02391024/3000 [=========>....................] - ETA: 1:08 - loss: 185531.1689 - MeanSquaredError: 0.1851 - KLDivergence: -0.02531088/3000 [=========>....................] - ETA: 1:04 - loss: 182563.1314 - MeanSquaredError: 0.1822 - KLDivergence: -0.02651152/3000 [==========>...................] - ETA: 1:01 - loss: 179680.9080 - MeanSquaredError: 0.1793 - KLDivergence: -0.0276